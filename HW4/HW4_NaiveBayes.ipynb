{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"languageID\"\n",
    "data_files = os.listdir(data_folder)\n",
    "\n",
    "languages = ['e', 's', 'j']\n",
    "training_files = []\n",
    "for l in languages:\n",
    "    for i in range(10):\n",
    "        filename = f\"{l}{i}.txt\"\n",
    "        file_path = os.path.join(data_folder, filename)\n",
    "        if os.path.exists(file_path):\n",
    "            training_files.append(filename)\n",
    "\n",
    "\n",
    "file_language_counts = []\n",
    "for l in languages:\n",
    "    file_language_counts.append(len([file for file in training_files if file.startswith(l)]))\n",
    "\n",
    "smooth_prior_probs = []\n",
    "alpha = 0.5\n",
    "for count in file_language_counts:\n",
    "    smooth_prior_probs.append((count+alpha)/(sum(file_language_counts)+alpha*len(languages)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('p̂(y=e) = '+str(smooth_prior_probs[0]))\n",
    "print('p̂(y=s) = '+str(smooth_prior_probs[1]))\n",
    "print('p̂(y=j) = '+str(smooth_prior_probs[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_cond_prob(lang_files, language):\n",
    "    char_counts = {char:0 for char in \"abcdefghijklmnopqrstuvwxyz \"}\n",
    "    total_chars = 0\n",
    "    for file in lang_files:\n",
    "        with open(os.path.join(\"languageID/\", file), \"r\") as f:\n",
    "            all_text = f.read()\n",
    "            for char in all_text:\n",
    "                if char in char_counts:\n",
    "                    char_counts[char] += 1\n",
    "                    total_chars += 1\n",
    "    \n",
    "    char_cond_probs = []\n",
    "    alpha = 0.5\n",
    "    for char in \"abcdefghijklmnopqrstuvwxyz \":\n",
    "        N_c = char_counts[char]\n",
    "        cond_prob = (N_c+alpha)/(total_chars+27*alpha)\n",
    "        char_cond_probs.append(cond_prob)\n",
    "        print(f\"θ{char},{language} = {cond_prob:.5f}\")\n",
    "    return char_cond_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_class_cond_prob([file for file in training_files if file.startswith('e')], 'e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_class_cond_prob([file for file in training_files if file.startswith('s')], 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_class_cond_prob([file for file in training_files if file.startswith('j')], 'j')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_count(lang_files):\n",
    "    char_counts = {char:0 for char in \"abcdefghijklmnopqrstuvwxyz \"}\n",
    "    total_chars = 0\n",
    "    for file in lang_files:\n",
    "        with open(os.path.join(\"languageID/\", file), \"r\") as f:\n",
    "            all_text = f.read()\n",
    "            for char in all_text:\n",
    "                if char in char_counts:\n",
    "                    char_counts[char] += 1\n",
    "                    total_chars += 1\n",
    "    char_counts_array = []\n",
    "    for char in \"abcdefghijklmnopqrstuvwxyz \":\n",
    "        N_c = char_counts[char]\n",
    "        char_counts_array.append(N_c)\n",
    "        print(f\"x_{char} = {N_c:.0f}\")\n",
    "    return char_counts_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_class_count([file for file in data_files if file.startswith('e10')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_likelihood(char_counts, class_cond_prob, vocab_size=27):\n",
    "    net_likelihood = 0\n",
    "    for i in range(vocab_size):\n",
    "        net_likelihood += char_counts[i]*np.log10(class_cond_prob[i])\n",
    "    return net_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_log_likelihoods = []\n",
    "\n",
    "for l in languages:\n",
    "    all_log_likelihoods.append(get_log_likelihood(get_class_count([file for file in data_files if file.startswith('e10')]), get_class_cond_prob([file for file in training_files if file.startswith(l)], l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_log_likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(f'log(p̂(x|y={languages[i]})) = {all_log_likelihoods[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10**all_log_likelihoods[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mpmath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpmath\n",
    "exp_values = []\n",
    "for i in range(3):\n",
    "    exp_values.append(mpmath.power(10, all_log_likelihoods[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(f'p̂(x|y={languages[i]}) = {exp_values[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net_count_vocab = get_class_count([file for file in training_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net_count_vocab_prob = [i/sum(net_count_vocab) for i in net_count_vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posterior_denom(char_count, net_count_vocab_prob, vocab_size=27):\n",
    "    constant_denom = 0\n",
    "    for i in range(vocab_size):\n",
    "        constant_denom += char_count[i]*np.log10(net_count_vocab_prob[i])\n",
    "    return constant_denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_denom = get_posterior_denom(get_class_count([file for file in data_files if file.startswith('e10')]), net_count_vocab_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_posteriors = []\n",
    "for i in range(3):\n",
    "    post = np.log10(smooth_prior_probs[i])+all_log_likelihoods[i]  #-constant_denom\n",
    "    all_posteriors.append(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(f'log(p̂(y={languages[i]}|x)) = {all_posteriors[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_posteriors = []\n",
    "for i in range(3):\n",
    "    exp_posteriors.append(mpmath.power(10, all_posteriors[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(f'p̂(y={languages[i]}|x) = {exp_posteriors[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_posteriors[0]/sum(exp_posteriors), exp_posteriors[1]/sum(exp_posteriors), exp_posteriors[2]/sum(exp_posteriors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(file, languages, training_files, smooth_prior_probs):\n",
    "    char_count_file = get_class_count([file])\n",
    "    all_log_likelihoods = []\n",
    "    for l in languages:\n",
    "        all_log_likelihoods.append(get_log_likelihood(char_count_file, get_class_cond_prob([file for file in training_files if file.startswith(l)], l)))\n",
    "    all_posteriors = []\n",
    "    for i in range(3):\n",
    "        post = np.log10(smooth_prior_probs[i])+all_log_likelihoods[i]\n",
    "        all_posteriors.append(post)\n",
    "    exp_posteriors = []\n",
    "    for i in range(3):\n",
    "        exp_posteriors.append(mpmath.power(10, all_posteriors[i]))\n",
    "    return languages[np.argmax(np.array(exp_posteriors))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = [file for file in data_files if file not in training_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_all_testfiles = []\n",
    "for file in test_files:\n",
    "    predictions_all_testfiles.append(get_prediction(file, languages, training_files, smooth_prior_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth = [file[0] for file in test_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat = {}\n",
    "for l in languages:\n",
    "    for k in languages:\n",
    "        confusion_mat[(l, k)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predictions_all_testfiles)):\n",
    "    confusion_mat[predictions_all_testfiles[i], groundtruth[i]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "data = []\n",
    "for l in languages:\n",
    "    arr = []\n",
    "    for k in languages:\n",
    "        arr.append(confusion_mat[l, k])\n",
    "    data.append(arr)\n",
    "    \n",
    "column_headers = [\"\", 'e', 'j', 'k']\n",
    "row_headers = ['e', 'j', 'k']\n",
    "\n",
    "table = tabulate(data, headers=column_headers, showindex=row_headers, tablefmt=\"grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'languageID/e11.txt'\n",
    "with open(input_file, 'r') as file:\n",
    "    text = file.read()\n",
    "    \n",
    "all_chars = list(text)\n",
    "random.shuffle(all_chars)\n",
    "\n",
    "text_shuffled = ''.join(all_chars)\n",
    "with open('languageID/shuffled_e11.txt', 'w') as file:\n",
    "    file.write(text_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prediction('shuffled_e11.txt', languages, training_files, smooth_prior_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
